{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of Deep Learning using PyTorch\n",
    "PyTorch is a Python package that allows for ease of creating ML models. It has a host of functions that make creating forward prop and back prop easier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This material was taught by Python Engineer on Youtube through his free course here: https://www.youtube.com/watch?v=c36lUUr864M&t=11623s. All props to him as his course is amazing and very thorough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Basics\n",
    "tensors are the basic units that you work with when creatin ML models. They are like numpy arrays and represent matrices, which allow you to perform calculations very quickly with matrix math compared to creating many for-loops to run through. This section has some basic things that you can do with pytorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating some tensors for use in the following sections\n",
    "x = torch.rand(5,3)\n",
    "y = torch.rand(5,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some element-wise operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2292, 1.6671, 2.0257],\n",
      "        [2.2280, 1.2170, 2.5544],\n",
      "        [1.9078, 1.8030, 2.2947],\n",
      "        [1.0955, 2.4344, 0.9027],\n",
      "        [0.9626, 0.9256, 2.3006]])\n",
      "tensor([[-0.0312, -0.6167, -0.6223],\n",
      "        [-0.7375, -0.4934, -0.9242],\n",
      "        [-0.4919, -0.3130, -0.8621],\n",
      "        [-0.6478, -0.6179, -0.3173],\n",
      "        [-0.6582, -0.4536, -0.3861]])\n",
      "tensor([[0.0112, 0.1701, 0.3064],\n",
      "        [0.4096, 0.0646, 0.6140],\n",
      "        [0.2465, 0.1737, 0.4423],\n",
      "        [0.0325, 0.5097, 0.0272],\n",
      "        [0.0152, 0.0253, 0.3538]])\n",
      "tensor([[32.0424,  1.6215,  1.6070],\n",
      "        [ 1.3559,  2.0268,  1.0821],\n",
      "        [ 2.0330,  3.1952,  1.1600],\n",
      "        [ 1.5438,  1.6183,  3.1511],\n",
      "        [ 1.5193,  2.2047,  2.5902]])\n"
     ]
    }
   ],
   "source": [
    "# element-wise and in-place addition\n",
    "a = torch.add(x, y)\n",
    "a.add_(x)\n",
    "\n",
    "# element-wise and in-place subtraction\n",
    "b = torch.sub(x, y)\n",
    "b.sub_(x)\n",
    "\n",
    "# element-wise and in-place multiplication\n",
    "c = torch.mul(x, y)\n",
    "c.mul_(x)\n",
    "\n",
    "# element-wise and in-place division\n",
    "d = torch.div(x, y)\n",
    "d.div_(x)\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5990, 0.5252, 0.7017],\n",
      "        [0.7453, 0.3618, 0.8151],\n",
      "        [0.7079, 0.7450, 0.7163],\n",
      "        [0.2239, 0.9082, 0.2927],\n",
      "        [0.1522, 0.2360, 0.9573]])\n",
      "tensor([0.5252, 0.3618, 0.7450, 0.9082, 0.2360])\n",
      "tensor([0.7453, 0.3618, 0.8151])\n",
      "tensor(0.3618)\n"
     ]
    }
   ],
   "source": [
    "# using the same tensors created in the section before\n",
    "print(x)      # show the entire tensor\n",
    "print(x[:,1]) # gets the first column\n",
    "print(x[1,:]) # gets the first row\n",
    "print(x[1,1]) # gets the value at the (1,1) space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resizing tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5990],\n",
      "        [0.5252],\n",
      "        [0.7017],\n",
      "        [0.7453],\n",
      "        [0.3618],\n",
      "        [0.8151],\n",
      "        [0.7079],\n",
      "        [0.7450],\n",
      "        [0.7163],\n",
      "        [0.2239],\n",
      "        [0.9082],\n",
      "        [0.2927],\n",
      "        [0.1522],\n",
      "        [0.2360],\n",
      "        [0.9573]])\n",
      "tensor([[0.0312, 0.6167, 0.6223, 0.7375, 0.4934],\n",
      "        [0.9242, 0.4919, 0.3130, 0.8621, 0.6478],\n",
      "        [0.6179, 0.3173, 0.6582, 0.4536, 0.3861]])\n"
     ]
    }
   ],
   "source": [
    "# use the view function - the product of the dimensions must be the same\n",
    "z = x.view(15, 1)\n",
    "print(z)\n",
    "z = y.view(-1, 5) # the -1 means 'whatever is left' - it will auto size\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting from numpy ndarrays to pytorch tensors and vice-versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.2291832 1.6671228 2.0256515]\n",
      " [2.2280378 1.2170306 2.5543995]\n",
      " [1.907757  1.8030319 2.2947206]\n",
      " [1.0954642 2.434426  0.9026909]\n",
      " [0.9625508 0.9256248 2.3006268]]\n",
      "tensor([[1.2292, 1.6671, 2.0257],\n",
      "        [2.2280, 1.2170, 2.5544],\n",
      "        [1.9078, 1.8030, 2.2947],\n",
      "        [1.0955, 2.4344, 0.9027],\n",
      "        [0.9626, 0.9256, 2.3006]])\n"
     ]
    }
   ],
   "source": [
    "# from tensor to ndarray\n",
    "e = a.numpy() # both e and a point to the same tensor - so changing one will change the other\n",
    "print(e)\n",
    "\n",
    "# from ndarray to tensor\n",
    "a = torch.from_numpy(e) # both e and a point to the same tensor - so changing one will change the other\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd\n",
    "autograd is a package in pytorch that allows for automatically creating gradient descent in pytorch tensors. <br>\n",
    "gradient descent and gradients are central to creating ML models because this is how you train a model. Therefore, this package is central to the pytorch <br>\n",
    "<br>\n",
    "When performing an operation on a tensor using autograd, pytorch creates a computation graph which automatically stores a function that is the gradient (slope) of the node. This is convenient for use during back propogation because the function is already stored rather than it needing to be calculated every time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autograd features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.6709, grad_fn=<MeanBackward0>)\n",
      "tensor([2.5158, 1.2880, 1.3419])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True) # let the tensor know whether it can use autograd\n",
    "\n",
    "y = x + 2        # creates a computation graph - has an attribute that is the derivative of tensor + 2\n",
    "z = y * y * 2\n",
    "z = z.mean()\n",
    "print(z)         # the 'grad_fn' attribute is the gradient function\n",
    "\n",
    "z.backward()     # backward propogation dcomp/dtensor - tensor has attribute that stores grad values\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of gradient calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "# with ML models, we need to calculate gradient descent - this is a simple example using a linear function\n",
    "weights = torch.ones(4, requires_grad=True)\n",
    "\n",
    "for epoch in range(3):\n",
    "    modelOutput = (weights * 3).sum()       # (weights * 3) is function, .sum() creates one attr so backwards() can be called\n",
    "    modelOutput.backward()\n",
    "    print(weights.grad)                     # if stop here, it will calculate the change from the starting position (ones)\n",
    "                                            # but, we want to calculate for each step, therefore, we reset the grads at each step\n",
    "    weights.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent using Autograd\n",
    "gradient descent is the backbone of ML models - it makes the model more accurate - this is a quick intro on using gradient descent with pytorch autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropogation\n",
    "backpropogation is an essential step in deep learning. Here, based on the accuracy of the forward propogation step, you calculate the gradient descent and which set of parameters to test next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., grad_fn=<PowBackward0>)\n",
      "tensor(-2.)\n"
     ]
    }
   ],
   "source": [
    "# initialize the input and expected result\n",
    "x = torch.tensor(1.0)\n",
    "y = torch.tensor(2.0)\n",
    "\n",
    "# initialize the weights\n",
    "w = torch.tensor(1.0, requires_grad=True)\n",
    "\n",
    "# forward pass and compute loss\n",
    "yhat = w * x\n",
    "loss = (yhat - y)**2\n",
    "print(loss)\n",
    "\n",
    "# backward pass and compute grads - computed automatically because we specified require_grad\n",
    "loss.backward()\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent\n",
    "In a typical ML model, you would throw all of this in a for loop and do it multiple times to make the prediction more accurate. This next portion will show that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using only numpy\n",
    "First, to ensure understanding of how these models work, implement using only numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: x=5, y=0.443697558796618\n",
      "epoch: 1, w: 0.8685338232827611, loss: 93.14936828613281\n",
      "epoch: 2, w: 1.330172006876511, loss: 32.64550018310547\n",
      "epoch: 3, w: 1.6034618017983862, loss: 11.441070556640625\n",
      "epoch: 4, w: 1.7652494147134252, loss: 4.00968599319458\n",
      "epoch: 5, w: 1.8610276663613745, loss: 1.405250072479248\n",
      "epoch: 6, w: 1.917728357584519, loss: 0.4924890398979187\n",
      "epoch: 7, w: 1.9512952177834937, loss: 0.17260020971298218\n",
      "epoch: 8, w: 1.9711667502236792, loss: 0.06048986315727234\n",
      "epoch: 9, w: 1.9829307158303686, loss: 0.021199584007263184\n",
      "epoch: 10, w: 1.9898950083566138, loss: 0.007429744116961956\n",
      "epoch: 11, w: 1.9940178454232642, loss: 0.0026038270443677902\n",
      "epoch: 12, w: 1.9964585588288732, loss: 0.0009125432115979493\n",
      "epoch: 13, w: 1.9979034765077062, loss: 0.00031982033397071064\n",
      "epoch: 14, w: 1.998758864910645, loss: 0.00011208475916646421\n",
      "epoch: 15, w: 1.9992652314019628, loss: 3.927803845726885e-05\n",
      "Prediction after training: x=5, y=9.996326157009815\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# linear regression so - function = weight * sample\n",
    "\n",
    "# initialize our training samples\n",
    "X = np.array([1,2,3,4,5,6,7,8], dtype=np.float32)\n",
    "Y = np.array([2,4,6,8,10,12,14,16], dtype=np.float32)\n",
    "\n",
    "# initialize our weight\n",
    "w = random.random()\n",
    "\n",
    "# calculate model prediction\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# calculate loss - mean squared error\n",
    "def loss(y, y_pred):\n",
    "    return ((y_pred - y)**2).mean()\n",
    "\n",
    "# calculate gradient - the derivative of the loss with respect to the weights\n",
    "def gradient(x, y, y_pred):\n",
    "    return np.dot(2*x, y_pred-y).mean()\n",
    "\n",
    "# prediction before training\n",
    "print('Prediction before training: x=5, y=' + str(w*5))\n",
    "\n",
    "# training the model\n",
    "lr = 0.001\n",
    "n_iters = 15\n",
    "epochs = []\n",
    "losses = []\n",
    "weights = []\n",
    "for epoch in range(1, n_iters+1):\n",
    "    # forward pass\n",
    "    y_pred = forward(X)\n",
    "\n",
    "    # compute the loss\n",
    "    l = loss(Y, y_pred)\n",
    "    epochs.append(epoch)\n",
    "    losses.append(l)\n",
    "\n",
    "    # update the weights\n",
    "    dW = gradient(X, Y, y_pred)\n",
    "    w -= lr * dW\n",
    "    weights.append(w)\n",
    "    \n",
    "    # update the epochs\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'epoch: {epoch}, w: {w}, loss: {l}')\n",
    "\n",
    "# print the loss\n",
    "plt.plot(epochs, losses)\n",
    "plt.plot(epochs, weights)\n",
    "\n",
    "# prediction after training\n",
    "print('Prediction after training: x=5, y=' + str(w*5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backprop with PyTorch\n",
    "for the backward propogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: x=5, y=0.0\n",
      "epoch: 2, w: 1.5197999477386475, loss: 24.49020004272461\n",
      "epoch: 4, w: 1.8847039937973022, loss: 1.4118115901947021\n",
      "epoch: 6, w: 1.9723174571990967, loss: 0.0813881903886795\n",
      "epoch: 8, w: 1.9933533668518066, loss: 0.004691871348768473\n",
      "epoch: 10, w: 1.9984041452407837, loss: 0.0002704716462176293\n",
      "epoch: 12, w: 1.9996168613433838, loss: 1.5594378055538982e-05\n",
      "epoch: 14, w: 1.9999079704284668, loss: 8.987138926386251e-07\n",
      "epoch: 16, w: 1.999977946281433, loss: 5.1823555224927986e-08\n",
      "epoch: 18, w: 1.9999946355819702, loss: 3.004425153108059e-09\n",
      "epoch: 20, w: 1.999998688697815, loss: 1.7278267705478356e-10\n",
      "Prediction after training: x=5, y=9.999993324279785\n"
     ]
    }
   ],
   "source": [
    "# linear regression so - function = weight * sample\n",
    "\n",
    "# initialize our training samples\n",
    "X = torch.tensor([1,2,3,4,5,6,7,8], dtype=torch.float32)\n",
    "Y = torch.tensor([2,4,6,8,10,12,14,16], dtype=torch.float32)\n",
    "\n",
    "# initialize our weight\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "# calculate model prediction\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# calculate loss - mean squared error\n",
    "def loss(y, y_pred):\n",
    "    return ((y_pred - y)**2).mean()\n",
    "\n",
    "# prediction before training\n",
    "print(f'Prediction before training: x=5, y={forward(5).item()}')\n",
    "\n",
    "# training the model\n",
    "lr = 0.01\n",
    "n_iters = 20\n",
    "epochs = []\n",
    "losses = []\n",
    "weights = []\n",
    "for epoch in range(1, n_iters+1):\n",
    "    # forward pass\n",
    "    y_pred = forward(X)\n",
    "\n",
    "    # compute the loss\n",
    "    l = loss(Y, y_pred)\n",
    "    epochs.append(epoch)\n",
    "    losses.append(l.item)\n",
    "\n",
    "    # update the weights\n",
    "    l.backward()\n",
    "    with torch.no_grad():\n",
    "        w -= lr * w.grad\n",
    "\n",
    "    # set the gradients to 0 again\n",
    "    weights.append(w.item)\n",
    "    w.grad.zero_()\n",
    "    \n",
    "    # update the epochs\n",
    "    if epoch % 2 == 0:\n",
    "        print(f'epoch: {epoch}, w: {w}, loss: {l}')\n",
    "\n",
    "# prediction after training\n",
    "print(f'Prediction after training: x=5, y={forward(5).item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Pipeline with PyTorch\n",
    "Using more pytorch modules including the optimizer and loss calculation<br>\n",
    "In training a model with PyTorch, use the following steps: <br>\n",
    "1. design the model (input size, output size, forward pass)\n",
    "2. construct the loss and optimizer\n",
    "3. create the training loop \n",
    "    1. forward pass...compute the prediction\n",
    "    2. backward pass...gradients\n",
    "    3. update the weights...to increase accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: x=5, y=2.543\n",
      "epoch: 10, w: 1.727, loss: 0.661\n",
      "epoch: 20, w: 1.914, loss: 0.021\n",
      "epoch: 30, w: 1.946, loss: 0.004\n",
      "epoch: 40, w: 1.952, loss: 0.003\n",
      "epoch: 50, w: 1.954, loss: 0.003\n",
      "epoch: 60, w: 1.956, loss: 0.003\n",
      "epoch: 70, w: 1.957, loss: 0.003\n",
      "epoch: 80, w: 1.958, loss: 0.003\n",
      "epoch: 90, w: 1.960, loss: 0.002\n",
      "epoch: 100, w: 1.961, loss: 0.002\n",
      "Prediction after training: x=5, y=9.804\n"
     ]
    }
   ],
   "source": [
    "# a new package\n",
    "import torch.nn as nn # a neural network module\n",
    "\n",
    "# linear regression so - function = weight * sample\n",
    "\n",
    "# initialize our training samples\n",
    "X = torch.tensor([[1],[2],[3],[4]], dtype=torch.float32)\n",
    "Y = torch.tensor([[2],[4],[6],[8]], dtype=torch.float32)\n",
    "XTest = torch.tensor([5], dtype=torch.float32)\n",
    "\n",
    "# get the size of input\n",
    "n_samples, n_features = X.size()\n",
    "\n",
    "inputSize = n_features\n",
    "outputsize = n_features\n",
    "\n",
    "# initialize the model\n",
    "model = nn.Linear(inputSize, outputsize)\n",
    "\n",
    "# prediction before training\n",
    "print(f'Prediction before training: x=5, y={model(XTest).item():.3f}')\n",
    "\n",
    "# training the model\n",
    "lr = 0.01\n",
    "n_iters = 100\n",
    "\n",
    "# define the loss and optimizer\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr)\n",
    "\n",
    "for epoch in range(1, n_iters+1):\n",
    "    # forward pass\n",
    "    y_pred = model(X)\n",
    "\n",
    "    # compute the loss\n",
    "    l = loss(Y, y_pred)\n",
    "\n",
    "    # update the weights\n",
    "    l.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # set the gradients to 0 again\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # update the epochs\n",
    "    if epoch % 10 == 0:\n",
    "        w, b = model.parameters()\n",
    "        print(f'epoch: {epoch}, w: {w[0][0]:.3f}, loss: {l:.3f}')\n",
    "\n",
    "# prediction after training\n",
    "print(f'Prediction after training: x=5, y={forward(5).item():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "This should be a review of using a very simple linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the pacakges\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a regression dataset\n",
    "x_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=1)\n",
    "\n",
    "# convert to tensors\n",
    "X = torch.from_numpy(x_numpy.astype(np.float32))\n",
    "Y = torch.from_numpy(y_numpy.astype(np.float32))\n",
    "\n",
    "# reshape and get the input/output sizes\n",
    "Y = Y.view(Y.shape[0], 1)\n",
    "n_samples, n_features = X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the parameters\n",
    "input_size = n_features\n",
    "output_size = 1\n",
    "\n",
    "# initialize the model\n",
    "model = nn.Linear(input_size, output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the loss\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# set the optimizer\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 100, loss: 332.5676, \n",
      "epoch: 200, loss: 332.5676, \n",
      "epoch: 300, loss: 332.5676, \n",
      "epoch: 400, loss: 332.5676, \n",
      "epoch: 500, loss: 332.5676, \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set the loop\n",
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # forward pass and loss\n",
    "    y_pred = model(X)\n",
    "    loss = criterion(y_pred, Y)\n",
    "\n",
    "    # backward pass \n",
    "    loss.backward()\n",
    "\n",
    "    #update the weights\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # print some info\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'epoch: {epoch+1}, loss: {loss.item():.4f}, ')\n",
    "\n",
    "# plot the values\n",
    "predicted = model(X).detach().numpy()\n",
    "plt.plot(x_numpy, y_numpy, 'ro')\n",
    "plt.plot(x_numpy, predicted, 'bo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "Using a new model type - but this should still be review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the breast cancer dataset from breast cancer dataset\n",
    "bc = datasets.load_breast_cancer()\n",
    "\n",
    "# load the input/output\n",
    "X, Y = bc.data, bc.target\n",
    "\n",
    "# get dataset size\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "# split the dataset\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "# scale the data from 0-1\n",
    "sc = StandardScaler()\n",
    "Xtrain = sc.fit_transform(Xtrain)\n",
    "XTest = sc.transform(Xtest)\n",
    "\n",
    "# create tensors from the ndarrays\n",
    "Xtrain = torch.from_numpy(Xtrain.astype(np.float32))\n",
    "Xtest = torch.from_numpy(Xtest.astype(np.float32))\n",
    "Ytrain = torch.from_numpy(Ytrain.astype(np.float32))\n",
    "Ytest = torch.from_numpy(Ytest.astype(np.float32))\n",
    "\n",
    "# reshape the Y to column vector\n",
    "Ytrain = Ytrain.view(Ytrain.shape[0], 1)\n",
    "Ytest = Ytest.view(Ytest.shape[0], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is not pre-defined class in PyTorch, so we'll need to create our own\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, n_input_features):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))\n",
    "        return y_pred\n",
    "\n",
    "# initialize the model\n",
    "logreg = LogisticRegression(n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the loss\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# set the optimizer\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(logreg.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 100, loss: 0.246405\n",
      "epoch: 200, loss: 0.186896\n",
      "epoch: 300, loss: 0.161085\n",
      "epoch: 400, loss: 0.145664\n",
      "epoch: 500, loss: 0.135096\n",
      "epoch: 600, loss: 0.127279\n",
      "epoch: 700, loss: 0.121203\n",
      "epoch: 800, loss: 0.116313\n",
      "epoch: 900, loss: 0.112273\n",
      "epoch: 1000, loss: 0.108867\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # forward pass and loss calc\n",
    "    Ypred = logreg(Xtrain)\n",
    "    loss = criterion(Ypred, Ytrain)\n",
    "\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # update params\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # gather some data\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'epoch: {epoch+1}, loss: {loss.item():.6f}')\n",
    "\n",
    "    plt.plot(epoch,loss.item(), 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.4035\n"
     ]
    }
   ],
   "source": [
    "# this piece of code has something wrong with it, but I have no clue what it is\n",
    "# when using the model - it only predicts zeros\n",
    "# this is not how it should work, in fact in the cell above, it works fine when the model() function is used for forward prop\n",
    "Ytestpred = logreg(Xtest)\n",
    "with torch.no_grad():\n",
    "    #y_predicted = logreg(Xtest) # this is the line I am referring to - it just returns all 0's and does not make a prediction\n",
    "    y_predicted_cls = Ytestpred.round()\n",
    "    acc = y_predicted_cls.eq(Ytest).sum() / float(Ytest.shape[0])\n",
    "    print(f'accuracy: {acc.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and Data Loader\n",
    "For samples that are really large, optimizing over the entire dataset is very timely and inefficient. Instead, we want to use the DataLoader class to create batches. Then, we perform iterations over the batches so that optimization is faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import outstanding packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement our custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WineDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        xy = np.loadtxt('/Users/sakinkirti/Programming/Python/pytorch-tutorial/wine.txt', delimiter=',', dtype=np.float32, skiprows=1)\n",
    "        self.x = torch.from_numpy(xy[:,1:])\n",
    "        self.y = torch.from_numpy(xy[:,[0]])\n",
    "        self.num_samples = xy.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to use the Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
      "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
      "        1.0650e+03]) tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "# using the Dataset\n",
    "dataset = WineDataset()\n",
    "firstData = dataset[0]\n",
    "features, labels = firstData\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to use the DataLoader class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3050e+01, 3.8600e+00, 2.3200e+00, 2.2500e+01, 8.5000e+01, 1.6500e+00,\n",
      "         1.5900e+00, 6.1000e-01, 1.6200e+00, 4.8000e+00, 8.4000e-01, 2.0100e+00,\n",
      "         5.1500e+02],\n",
      "        [1.3050e+01, 1.6500e+00, 2.5500e+00, 1.8000e+01, 9.8000e+01, 2.4500e+00,\n",
      "         2.4300e+00, 2.9000e-01, 1.4400e+00, 4.2500e+00, 1.1200e+00, 2.5100e+00,\n",
      "         1.1050e+03],\n",
      "        [1.3290e+01, 1.9700e+00, 2.6800e+00, 1.6800e+01, 1.0200e+02, 3.0000e+00,\n",
      "         3.2300e+00, 3.1000e-01, 1.6600e+00, 6.0000e+00, 1.0700e+00, 2.8400e+00,\n",
      "         1.2700e+03],\n",
      "        [1.2450e+01, 3.0300e+00, 2.6400e+00, 2.7000e+01, 9.7000e+01, 1.9000e+00,\n",
      "         5.8000e-01, 6.3000e-01, 1.1400e+00, 7.5000e+00, 6.7000e-01, 1.7300e+00,\n",
      "         8.8000e+02]]) tensor([[2.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [3.]])\n"
     ]
    }
   ],
   "source": [
    "# using the DataLoader\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=4, shuffle=True)\n",
    "dataiter = iter(dataloader)\n",
    "data = dataiter.next()\n",
    "features, labels = data\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A short example of how to use the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/2, step: 5/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step: 10/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step: 15/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step: 20/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step: 25/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step: 30/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step: 35/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step: 40/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step: 45/45, inputs: torch.Size([2, 13])\n",
      "epoch: 2/2, step: 5/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step: 10/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step: 15/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step: 20/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step: 25/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step: 30/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step: 35/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step: 40/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step: 45/45, inputs: torch.Size([2, 13])\n"
     ]
    }
   ],
   "source": [
    "# using the dataloader in practing\n",
    "num_epochs = 2\n",
    "total_samples = len(dataset)\n",
    "n_iters = math.ceil(total_samples / 4)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        if (i+1) % 5 == 0:\n",
    "            print(f'epoch: {epoch+1}/{num_epochs}, step: {i+1}/{n_iters}, inputs: {inputs.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Transforms\n",
    "This allows us to automatically transform a dataset when loading it from pytorch. This can be very helpful to convert images to tenors, etc <br>\n",
    "Check the documentation for the full list of transforms avaialable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding to the Wine Dataset class\n",
    "The dataset transforms can be done by adding to a dataset class. This is the exact class from the dataset tutorial above, which I am adding to by adding additional transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wine dataset class with some additions\n",
    "class WineDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        xy = np.loadtxt('/Users/sakinkirti/Programming/Python/pytorch-tutorial/wine.txt', delimiter=',', dtype=np.float32, skiprows=1)\n",
    "        self.x = xy[:,1:]\n",
    "        self.y = xy[:,[0]]\n",
    "        self.num_samples = xy.shape[0]\n",
    "\n",
    "        self.transform = transform # addition\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.x[index], self.y[index]\n",
    "\n",
    "        if self.transform: # addition\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a ToTensor class that will convert our dataset to tensors\n",
    "class ToTensor:\n",
    "    def __call__(self, sample):\n",
    "        inputs, labels = sample\n",
    "        return torch.from_numpy(inputs), torch.from_numpy(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another transform\n",
    "class MulTransform:\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        inputs, labels = sample\n",
    "        inputs *= self.factor\n",
    "        return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
      " 2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03] [1.]\n"
     ]
    }
   ],
   "source": [
    "# call the dataset\n",
    "data = WineDataset(transform=None)\n",
    "\n",
    "# get an item - this applies does not apply a transform\n",
    "firstItem = data[0]\n",
    "features, labels = firstItem\n",
    "print(type(features), type(labels))\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
      " 2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03] tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "# here, i use the compose transform to put multiple transforms together\n",
    "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(2)])\n",
    "data = WineDataset(transform=composed)\n",
    "firstItem = data[0]\n",
    "inputs, labels = firstItem\n",
    "print(type(inputs), type(labels))\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax and Cross Entropy\n",
    "A softmax function is regularly used in multi-class classification problems. These are fairly regularly used in ML models. Cross entropy is a type of loss function that is pretty regularly in many ML models. Here is how to use them with PyTorch\n",
    "<br><br>\n",
    "A softmax layer outputs values at each node between 0 and 1, such that the sum of all of the values adds to 1. From here, one can filter as needed (highest value, top 5 values, least 5 values, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Math behind softmax\n",
    "e^y(i) / sum( e^y(j) ) <br>\n",
    "This squashes the output to be between 0 and 1. They are probabilities of a particular output. The highest probability is typically the y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Softmax function in code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to calculate the softmax\n",
    "def softmax(y):\n",
    "    return np.exp(y) / np.sum(np.exp(y), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 4 3 2 1 0]\n",
      "[0.63369132 0.23312201 0.08576079 0.03154963 0.01160646 0.00426978]\n"
     ]
    }
   ],
   "source": [
    "# a quick example using this softmax function\n",
    "x = np.array([5,4,3,2,1,0])\n",
    "output = softmax(x)\n",
    "print(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 4., 3., 2., 1., 0.])\n",
      "tensor([0.6337, 0.2331, 0.0858, 0.0315, 0.0116, 0.0043])\n"
     ]
    }
   ],
   "source": [
    "# calculating with pytorch\n",
    "x = torch.tensor([5.0,4.0,3,2,1,0])\n",
    "outputs = torch.softmax(x, dim=0)\n",
    "print(x)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Entropy Loss\n",
    "The softmax layer is often used in conjunction with the Cross-Entropy Loss because it is used with layers that output a probability\n",
    "#### Math behind CEL\n",
    "(-1/N) * sum(y(i) * log(yhat(i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CEL in code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good cross entropy loss: 0.13586865481479343\n",
      "bad cross entropy loss: 0.80253532148146\n"
     ]
    }
   ],
   "source": [
    "# create a cross-entropy loss function\n",
    "def cross_entropy(y, yhat):\n",
    "    return -(sum(y * np.log(yhat))) / float(yhat.shape[0])\n",
    "\n",
    "# create the arrays\n",
    "y = np.array([1,0,0])\n",
    "ygood = softmax(np.array([5,4,3]))\n",
    "ybad = softmax(np.array([3,5,4]))\n",
    "\n",
    "# calculate CEL\n",
    "outputg = cross_entropy(y, ygood)\n",
    "outputb = cross_entropy(y, ybad)\n",
    "print(f'good cross entropy loss: {output}')\n",
    "print(f'bad cross entropy loss: {outputb}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CEL with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good loss: 0.4170299470424652\n",
      "bad loss: 2.342207193374634\n"
     ]
    }
   ],
   "source": [
    "# declare the loss func\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# create the labels\n",
    "y = torch.tensor([0])\n",
    "ygood = torch.tensor([[2.0, 1.0, 0.1]])\n",
    "ybad = torch.tensor([[0.1, 2.0, 1.1]])\n",
    "\n",
    "# call loss func\n",
    "goodL = loss(ygood, y)\n",
    "badL = loss(ybad, y)\n",
    "\n",
    "# print\n",
    "print(f'good loss: {goodL.item()}')\n",
    "print(f'bad loss: {badL.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good pred: 0, bad pred: 1\n"
     ]
    }
   ],
   "source": [
    "# to get the prediction from PyTorch, use this func\n",
    "_, predsg = torch.max(ygood, 1)\n",
    "_, predsb = torch.max(ybad, 1)\n",
    "\n",
    "# choose the value with the highest probability\n",
    "print(f'good pred: {predsg.item()}, bad pred: {predsb.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions with Pytorch\n",
    "activtion functions allow data to travel through NN hidden layers. They apply a linear transformation to the function to decide whether the next neuron should be activated or not. These can use linear, ReLU, or some other functions. When needed, can search up what the math is. These are some different activation functions:\n",
    "- linear\n",
    "- sigmoid\n",
    "- tanh\n",
    "- ReLU\n",
    "- Leaky ReLU\n",
    "- softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways we can implement activation functions in Pytorch. One, is with nn modules that pytorch supplies. It is shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetStepwise:\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNetStepwise, self).__init__()\n",
    "\n",
    "        # the first layer, followed by its activation\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # the second layer, followed by its activation\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # pass the input throught the layers\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second way is to use these functions directly - this can make code less cluttered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetInPlace:\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNetInPlace, self).__init__()\n",
    "\n",
    "        # the first layer\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        # the second layer\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(x):\n",
    "        # we do the activation in place by applying the activation function directly\n",
    "        out = torch.nn.ReLU(self.linear1(x))\n",
    "        out = torch.nn.Sigmoid(self.linear2(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward Net\n",
    "An example of a simple neural network. This will be a multilayer multiclass model using the MNIST dataset. This dataset has handwritten numbers in which we want to NN to classify these characters are each number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784 # images are 28 x 28\n",
    "hidden_size = 100\n",
    "num_classes = 10\n",
    "num_epochs = 3\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the datasets\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "# use a dataloader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# look at one set\n",
    "examples = iter(train_loader)\n",
    "samples, labels = examples.next()\n",
    "print(samples.shape, labels.shape)\n",
    "\n",
    "# show some data\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(samples[i][0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define our NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        # create the layers\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        return out\n",
    "\n",
    "# instantiate the model\n",
    "model = Network(input_size=input_size, hidden_size=hidden_size, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/3, step: 100/600, loss: 0.49884\n",
      "epoch: 1/3, step: 200/600, loss: 0.28134\n",
      "epoch: 1/3, step: 300/600, loss: 0.27290\n",
      "epoch: 1/3, step: 400/600, loss: 0.33269\n",
      "epoch: 1/3, step: 500/600, loss: 0.28581\n",
      "epoch: 1/3, step: 600/600, loss: 0.14551\n",
      "epoch: 2/3, step: 100/600, loss: 0.24196\n",
      "epoch: 2/3, step: 200/600, loss: 0.27990\n",
      "epoch: 2/3, step: 300/600, loss: 0.25892\n",
      "epoch: 2/3, step: 400/600, loss: 0.10054\n",
      "epoch: 2/3, step: 500/600, loss: 0.16690\n",
      "epoch: 2/3, step: 600/600, loss: 0.19865\n",
      "epoch: 3/3, step: 100/600, loss: 0.09282\n",
      "epoch: 3/3, step: 200/600, loss: 0.20492\n",
      "epoch: 3/3, step: 300/600, loss: 0.16794\n",
      "epoch: 3/3, step: 400/600, loss: 0.16112\n",
      "epoch: 3/3, step: 500/600, loss: 0.14187\n",
      "epoch: 3/3, step: 600/600, loss: 0.08895\n"
     ]
    }
   ],
   "source": [
    "n_total_steps = len(train_loader)\n",
    "\n",
    "# loop over epochs\n",
    "for epoch in range(num_epochs):\n",
    "    # loop over minibatches\n",
    "    for i,(images,labels) in enumerate(train_loader):\n",
    "\n",
    "        # reshape the images to column vectors - currently they are 100,1,28,28 while input size is 100,784\n",
    "        images = images.reshape(-1, 28*28)\n",
    "\n",
    "        # forward prop\n",
    "        y_pred = model(images)\n",
    "        l = loss(y_pred, labels)\n",
    "\n",
    "        # back prop\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print some data\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'epoch: {epoch+1}/{num_epochs}, step: {i+1}/{n_total_steps}, loss: {l.item():.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9624\n"
     ]
    }
   ],
   "source": [
    "# get the accuracy of the model\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        outputs = model(images)\n",
    "\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = n_correct / n_samples\n",
    "    print(f'Accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "018424330fd2776b878de25387691c469f53901b81fab446e5c14eecfc2492a5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
